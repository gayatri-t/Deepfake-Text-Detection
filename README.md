# Deepfake Text Detection & Adversarial Robustness Evaluation

## Overview
This project evaluates state-of-the-art defenses against synthetic (deepfake) text generated by advanced language models like GPT-4. We assess their real-world applicability and robustness against adaptive adversarial attacks, including low-cost perturbations (DFTFooler) and decoding strategy modifications. Our work introduces four real-world datasets and provides insights into improving detection frameworks.

## Key Features
- **Real-World Datasets**: Synthetic text collected from SEO platforms, Reddit GPT-3 bots, and GPT-4-generated articles.
- **Defense Models**: Evaluated BERT-Defense, GLTR-BERT, GLTR-GPT2, GROVER, FAST, and RoBERTa-Defense.
- **Adversarial Attacks**: Implemented DFTFooler (BERT/GPT2-XL backend) and decoding strategies (beam search, top-k, top-p) to test defense robustness.
- **Metrics**: F1 scores, precision/recall, and GRUEN scores for linguistic quality post-attack.
